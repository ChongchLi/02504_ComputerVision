{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epipolar geometry\n",
    "set up two cameras, both with the internal parameters,\n",
    "$$\n",
    "K = \\begin{bmatrix}\n",
    "1000 & 0 & 300 \\\\ 0 & 1000 & 200 \\\\ 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Now, for the first camera — let us call that Cam1 — set the rotation to identity $R1 = I$ and set the translation to zero $t1 = 0$. For the second camera $Cam2$ use the rotation given by the $R$ function\n",
    "$$\n",
    "R_2 = R(0.7,-0.5,0.8) \\\\\n",
    "R(\\theta_x, \\theta_y, \\theta_z) = \\begin{bmatrix}\n",
    "cos(\\theta_z) & -sin(\\theta_z) & 0 \\\\ sin(\\theta_z) & cos(\\theta_z) & 0 \\\\ 0 & 0 & 1\n",
    "\\end{bmatrix}  \\begin{bmatrix}\n",
    "cos(\\theta_y) & 0 & sin(\\theta_y) \\\\ 0 & 0 & 1 \\\\ -sin(\\theta_y) & 0 & cos(\\theta_y)\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "1 & 0 & 0\\\\ 0 & cos(\\theta_x) & -sin(\\theta_x) \\\\ 0 & sin(\\theta_x) & cos(\\theta_x)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "and the translation\n",
    "$$\n",
    "t_2 = \\begin{bmatrix} 0.2 \\\\ 2 \\\\ 1 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The rotation can be constructed in Python using Rotation module from scipy as follows:\n",
    "```\n",
    "from scipy.spatial.transform import Rotation\n",
    "R2 = Rotation.from_euler('xyz', [0.7, -0.5, 0.8]).as_matrix()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1\n",
    "Consider the 3D point\n",
    "$$\n",
    "Q = \\begin{bmatrix} 1 \\\\ 0.5 \\\\ 4 \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "and find the projections in $Cam1$ and $Cam2$, respectively, points $q1$ and $q2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 = \n",
      " [[550.]\n",
      " [325.]]\n",
      "q2 = \n",
      " [[582.473]\n",
      " [185.99 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# converts from homogeneous to inhomogeneous coordinates\n",
    "def Pi(ph):\n",
    "    return ph[:-1]/ph[-1]\n",
    "    \n",
    "# converts from inhomogeneous to homogeneous coordinates\n",
    "def PiInv(p):\n",
    "    ones = np.ones((1, p.shape[1]))\n",
    "    ph = np.vstack((p, ones))\n",
    "    return ph\n",
    "\n",
    "def projectpoints(K, R, t, Q):\n",
    "    Q_homogeneous = PiInv(Q)\n",
    "    q = np.hstack((R,t)) @ Q_homogeneous\n",
    "    P = Pi(q)\n",
    "    p = K @ PiInv(P)\n",
    "    return p\n",
    "\n",
    "K = np.array([[1000,0,300],[0,1000,200],[0,0,1]])\n",
    "R1 = np.eye(3)\n",
    "R2 = Rotation.from_euler('xyz', [0.7, -0.5, 0.8]).as_matrix()\n",
    "t1 = np.zeros((3,1))\n",
    "t2 = np.array([[0.2,2,1]]).T\n",
    "Q = np.array([[1,0.5,4,1]]).T\n",
    "\n",
    "q1 = projectpoints(K, R1, t1, Pi(Q))\n",
    "q2 = projectpoints(K, R2, t2, Pi(Q))\n",
    "\n",
    "print('q1 = \\n', Pi(q1))\n",
    "print('q2 = \\n', Pi(q2).round(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2\n",
    "Implement a function CrossOp that takes a vector in 3D and returns the 3×3 matrix corresponding to taking the cross product with that vector. In the case that $p = \\begin{bmatrix} x & y & z \\end{bmatrix}^T $ you should have\n",
    "$$\n",
    "CrossOp(p) = [p]_\\times = \\begin{bmatrix} 0 & -z & y \\\\ z & 0 & -x \\\\ -y & 0 & x \\end{bmatrix}\n",
    "$$\n",
    "As a good habit, verify that your function works by testing it on random vectors to ensure that\n",
    "$$\n",
    "[p_1]_\\times p_2 = p_1 \\times p_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[p1]xp2 =  [ 0.04760704  0.0246399  -0.17023855]\n",
      "p1 x p2 =  [ 0.04760704  0.0246399  -0.17023855]\n"
     ]
    }
   ],
   "source": [
    "def CrossOp(p):\n",
    "    p = np.array(p).flatten()\n",
    "    return np.array([[0, -p[2], p[1]],\n",
    "                     [p[2], 0, -p[0]],\n",
    "                     [-p[1], p[0], 0]])\n",
    "\n",
    "p1 = np.random.rand(3)\n",
    "p2 = np.random.rand(3)\n",
    "print(\"[p1]xp2 = \", CrossOp(p1) @ p2)\n",
    "print(\"p1 x p2 = \", np.cross(p1,p2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3\n",
    "Compute the fundamental matrix $F$ of the two cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.29311881e-07  8.19396327e-07  1.79162592e-03]\n",
      " [ 5.15532551e-07 -8.76915984e-07  9.31426656e-05]\n",
      " [-1.29882755e-03  1.51951700e-03 -1.10072682e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate essential matrix E\n",
    "E = CrossOp(t2) @ R2\n",
    "# Calculate fundamental matrix F\n",
    "F = np.linalg.inv(K).T @ E @ np.linalg.inv(K)\n",
    "print(F)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4\n",
    "What is the epipolar line $l$ of $q_1$ in camera two?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.23905126e-03]\n",
      " [ 9.16878739e-05]\n",
      " [-1.32123895e+00]]\n"
     ]
    }
   ],
   "source": [
    "l_q1 = F @ q1\n",
    "print(l_q1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.5\n",
    "Is $q_2$ located on the epipolar line from Exercise 3.4? Do the computations, but also explain why this must be so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.440892098500626e-16\n"
     ]
    }
   ],
   "source": [
    "print((q2.T@l_q1)[0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This prints -4.44089209850063e-16, which is very close to zero, indicating that $q_2$ is indeed located on the epipolar line.\n",
    "\n",
    ">This is expected, because $q_1$ and $q_2$ correspond to the same 3D point in the scene, and their projections onto the two image planes must be related by the epipolar geometry. In particular, the epipolar line corresponding to $q_1$ must pass through the projection of $q_2$ in the second image, and vice versa. Therefore, $q_2$ must lie on the epipolar line corresponding to $q_1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.6\n",
    "Now assume that both camera one and two have local coordinate systems that are different from the coordinate system of the world.\n",
    "\n",
    "Let $Q$ and $\\tilde{Q}$ denote the same 3D point in world space and in the frame of camera one. In other\n",
    "words we have relation\n",
    "$$\n",
    "\\tilde{Q} = \\begin{bmatrix} R_1 & t_1 \\\\ 0 & 1 \\end{bmatrix} Q\n",
    "$$\n",
    "Make sure you understand why this is true.\n",
    "\n",
    "Show analytically that \n",
    "$$\n",
    "Q = \\begin{bmatrix} R_1^T & - R_1^T t_1 \\\\ 0 & 1 \\end{bmatrix} \\tilde{Q}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $ \\tilde{Q} = \\begin{bmatrix} R_1 & t_1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} R_1^T & - R_1^T t_1 \\\\ 0 & 1 \\end{bmatrix} \\tilde{Q} \\\\\n",
    "\\tilde{Q} = \\begin{bmatrix} R_1 R_1^T & -R_1 R_1^T t_1 + t_1 \\\\ 0 & 1 \\end{bmatrix} \\tilde{Q} \\\\ \\tilde{Q} = \\begin{bmatrix} I & 0 \\\\ 0 & 1 \\end{bmatrix} \\tilde{Q} . $ \\\n",
    "> And we find that it is valid! This is true as the matrices are inverses of each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.7\n",
    "Show that the projection can work only in the coordinate system of camera one, by showing that we can project points with\n",
    "$$\n",
    "q_1 = K \\begin{bmatrix} I & 0 \\end{bmatrix} \\tilde{Q}\n",
    "$$\n",
    "$$\n",
    "q_2 = K \\begin{bmatrix} \\tilde{R}_2 & \\tilde{t}_2 \\end{bmatrix} \\tilde{Q} \n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\tilde{R}_2 = R_2 R_1^T, \\tilde{t}_2 = t_2 - R_2 R_1^T t_1 .\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied epipolar geometry\n",
    "### Exercise 3.8\n",
    "Load the file TwoImageData.npy, and compute the fundamental matrix between camera one and two. \\\n",
    "$Tip$: You can load the file with:\n",
    "```\n",
    "np.load('TwoImageData.npy', allow_pickle=True).item()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.9\n",
    "Write code that can show both images at the same time. Now write code such that you can click on a point in image one, and display the corresponding epipolar line in image two. Experiment with your code, verifying that the point you click on is on the epipolar line in the other image.\n",
    "\n",
    "$Tip$: To click on a point and get the pixel coordinates you can use plt.ginput(1). If you are using Jupyter notebook you might need to run %matplotlib qt first\n",
    "\n",
    "$Tip$: To draw a line given in homogeneous coordinates, you can use the DrawLine function below.\\\n",
    "It takes as input a line in homogeneous coordinates l and the size of the image it will be drawn on, as returned by im.shape.\n",
    "```\n",
    "def DrawLine(l, shape):\n",
    "    #Checks where the line intersects the four sides of the image\n",
    "    # and finds the two intersections that are within the frame\n",
    "    def in_frame(l_im):\n",
    "        q = np.cross(l.flatten(), l_im)\n",
    "        q = q[:2]/q[2]\n",
    "        if all(q>=0) and all(q+1<=shape[1::-1]):\n",
    "            return q\n",
    "    lines = [[1, 0, 0], [0, 1, 0], [1, 0, 1-shape[1]], [0, 1, 1-shape[0]]]\n",
    "    P = [in_frame(l_im) for l_im in lines if in_frame(l_im) is not None]\n",
    "    plt.plot(*np.array(P).T)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.10\n",
    "Do the same thing as the last exercise, but where you can click in image two and get the epipolar\n",
    "line displayed in image one.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.11\n",
    "Create a function triangulate. It should be able to triangulate a single 3D point that has been seen by n different cameras. The function should take as input: a list of n pixel coordinates (q1, q2, . . . , qn), and a list of n projection matrices (P1, P2, . . . , Pn), and should return the triangulation of the point in 3D using the linear algorithm. \\\n",
    "Test your function by defining a 3D point, project this point to the image planes of the two cameras, and then triangulate it using the projection. Try reprojecting your estimated 3D point to the cameras. Do you find the same 2D pixels?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fa3bc410bd5ebe59a6de1fb321c9d3b904b2a283ae1a66912e9a66895cfb30c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
